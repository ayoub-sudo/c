{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de code-final.ipynb","provenance":[],"mount_file_id":"125pycBIQGBNPJ-Ew0O3Ow-8vbVydCXBy","authorship_tag":"ABX9TyO37mKZKwBV/EejHs/hGHJM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"dWzFixuBq-E7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624658956074,"user_tz":-60,"elapsed":43822,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"1b9e69db-b88e-453d-ad0a-da93987aa1f4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gsY_v1dVrDQ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624714941755,"user_tz":-60,"elapsed":2177,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"cc0990cc-3374-4934-a4f2-d80abbd5f0a4"},"source":["\n","from keras.preprocessing.image import img_to_array, load_img\n","import numpy as np\n","import glob\n","\n","\n","class dataProcess(object):\n","    def __init__(self, out_rows, out_cols, data_path=\"/content/drive/MyDrive/U-Net2/data/train/images\", label_path=\"/content/drive/MyDrive/U-Net2/data/train/labels\",\n","                 test_path=\"/content/drive/MyDrive/U-Net2/data/test/images\", npy_path=\"/content/drive/MyDrive/U-Net2/data/npydata\", img_type=\"jpg\"):\n","        self.out_rows = out_rows\n","        self.out_cols = out_cols\n","        self.data_path = data_path\n","        self.label_path = label_path\n","        self.img_type = img_type\n","        self.test_path = test_path\n","        self.npy_path = npy_path\n","\n","   \n","    def create_train_data(self):\n","        i = 0\n","        print('Creating training images...')\n","        imgs = glob.glob(self.data_path+\"/*.\"+self.img_type)\n","        print(len(imgs))\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n","\n","        for x in range(len(imgs)):\n","            imgpath = imgs[x]\n","            pic_name = imgpath.split('/')[-1]\n","            labelpath = self.label_path + '/' + pic_name\n","            img = load_img(imgpath, grayscale=False, target_size=[512, 512])\n","            label = load_img(labelpath, grayscale=True, target_size=[512, 512])\n","            img = img_to_array(img)\n","            label = img_to_array(label)\n","            imgdatas[i] = img\n","            imglabels[i] = label\n","            if i % 100 == 0:\n","                print('Done:', len(imgs),' images')\n","            i += 1\n","\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n","        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n","        print('Saving to .npy files done.')\n","\n","    def create_test_data(self):\n","        i = 0\n","        print('Creating test images...')\n","        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        testpathlist = []\n","\n","        for imgname in imgs:\n","            testpath = imgname\n","            testpathlist.append(testpath)\n","            img = load_img(testpath, grayscale=False, target_size=[512, 512])\n","            img = img_to_array(img)\n","            imgdatas[i] = img\n","            i += 1\n","\n","        txtname = '/content/drive/MyDrive/U-Net2/data/results/pic.txt'\n","        with open(txtname, 'w') as f:\n","            for i in range(len(testpathlist)):\n","                f.writelines(testpathlist[i] + '\\n')\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n","        print('Saving to imgs_test.npy files done.')\n","\n","    def load_train_data(self):\n","        print('load train images...')\n","        imgs_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_train.npy\")\n","        imgs_mask_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_mask_train.npy\")\n","        imgs_train = imgs_train.astype('float32')\n","        imgs_mask_train = imgs_mask_train.astype('float32')\n","        imgs_train /= 255\n","        imgs_mask_train /= 255\n","        imgs_mask_train[imgs_mask_train > 0.5] = 1  \n","        imgs_mask_train[imgs_mask_train <= 0.5] = 0 \n","        return imgs_train, imgs_mask_train\n","\n","    def load_test_data(self):\n","        print('-' * 30)\n","        print('load test images...')\n","        print('-' * 30)\n","        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n","        imgs_test = imgs_test.astype('float32')\n","        imgs_test /= 255\n","        return imgs_test\n","\n","\n","\n","if __name__ == \"__main__\":\n","    mydata = dataProcess(512, 512)\n","    mydata.create_train_data()\n","    mydata.create_test_data()\n","\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import array_to_img\n","import cv2\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating training images...\n","36\n","Done: 36  images\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["loading done\n","Saving to .npy files done.\n","Creating test images...\n","loading done\n","Saving to imgs_test.npy files done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QkPzC_FErFJU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624714951219,"user_tz":-60,"elapsed":1971,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"60933f33-63a1-4839-dc96-bb7c36c6bc35"},"source":["# -*- coding:utf-8 -*-\n","\n","class myUnet(object):\n","      def __init__(self, img_rows=512, img_cols=512):\n","        self.img_rows = img_rows\n","        self.img_cols = img_cols\n","      def load_data(self):\n","        mydata = dataProcess(self.img_rows, self.img_cols)\n","        imgs_train, imgs_mask_train = mydata.load_train_data()\n","        imgs_test = mydata.load_test_data()\n","        return imgs_train, imgs_mask_train, imgs_test\n","      def get_unet(self):\n","        inputs = Input((self.img_rows, self.img_cols, 3))\n","\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","        # print(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","        print (\"pool1 shape:\", pool1.shape)\n","\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","        print (\"pool2 shape:\", pool2.shape)\n","\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","        print (\"pool3 shape:\", pool3.shape)\n","\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","        conv4 = BatchNormalization()(conv4)\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","        conv4 = BatchNormalization()(conv4)\n","        drop4 = Dropout(0.5)(conv4)\n","        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n","        conv5 = BatchNormalization()(conv5)\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","        conv5 = BatchNormalization()(conv5)\n","        drop5 = Dropout(0.5)(conv5)\n","\n","        up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n","        up6 = BatchNormalization()(up6)\n","        merge6 = concatenate([drop4, up6], axis=3)\n","        print(up6)\n","        print(merge6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv6))\n","        up7 = BatchNormalization()(up7)\n","        merge7 = concatenate([conv3, up7], axis=3)\n","        print(up7)\n","        print(merge7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","        conv7 = BatchNormalization()(conv7)\n","        print(conv7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n","        print(conv7)\n","        conv7 = BatchNormalization()(conv7)\n","        up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv7))\n","        up8 = BatchNormalization()(up8)\n","        merge8 = concatenate([conv2, up8], axis=3)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n","        conv8 = BatchNormalization()(conv8)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n","        conv8 = BatchNormalization()(conv8)\n","        up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv8))\n","        up9 = BatchNormalization()(up9)\n","        merge9 = concatenate([conv1, up9], axis=3)\n","        print(up9)\n","        print(merge9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print (\"conv9 shape:\", conv9.shape)\n","\n","        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n","        print(conv10)\n","        model = Model(inputs=inputs, outputs=conv10)\n","\n","        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","        return model\n","      def train(self):\n","        print(\"loading data\")\n","        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n","        print(\"loading data done\")\n","        model = self.get_unet()\n","        print(\"got unet\")\n","        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n","        print('Fitting model...')\n","        model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=100, verbose=1,\n","                  validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n","        model.save_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","        print('predict test data')\n","        imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","        np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","\n","      def save_img(self):\n","        print(\"array to image\")\n","        imgs = np.load('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy')\n","        piclist = []\n","        for line in open(\"/content/drive/MyDrive/U-Net2/data/results/pic.txt\"):\n","            line = line.strip()\n","            picname = line.split('/')[-1]\n","            piclist.append(picname)\n","        print(len(piclist))\n","        for i in range(imgs.shape[0]):\n","            path = \"/content/drive/MyDrive/U-Net2/data/test/\" + piclist[i]\n","            img = imgs[i]\n","            img = array_to_img(img)\n","            img.save(path)\n","            cv_pic = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","            cv_pic = cv2.resize(cv_pic,(1918,1280),interpolation=cv2.INTER_CUBIC)\n","            binary, cv_save = cv2.threshold(cv_pic, 127, 255, cv2.THRESH_BINARY)\n","            cv2.imwrite(path, cv_save)\n","      def load_model_weights(self, model):\n","        model.load_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","\n","\n","\n","myunet = myUnet()\n","model = myunet.get_unet()\n","    # model.summary()\n","    # plot_model(model, to_file='model.png')\n","    # Uncomment the below line if you want to re-train a previously trained model \n","#myunet.load_model_weights(model)\n","#imgs_test = mydata.load_test_data()\n","#imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","#np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","#myunet.save_img()\n","\n","#myunet.train()    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["conv1 shape: (None, 512, 512, 64)\n","conv1 shape: (None, 512, 512, 64)\n","pool1 shape: (None, 256, 256, 64)\n","conv2 shape: (None, 256, 256, 128)\n","conv2 shape: (None, 256, 256, 128)\n","pool2 shape: (None, 128, 128, 128)\n","conv3 shape: (None, 128, 128, 256)\n","conv3 shape: (None, 128, 128, 256)\n","pool3 shape: (None, 64, 64, 256)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='batch_normalization_194/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_194'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate_32/concat:0', description=\"created by layer 'concatenate_32'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_203/Relu:0', description=\"created by layer 'conv2d_203'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_204/Relu:0', description=\"created by layer 'conv2d_204'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_197/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_197'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_33/concat:0', description=\"created by layer 'concatenate_33'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_198/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_198'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_207/Relu:0', description=\"created by layer 'conv2d_207'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_203/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_203'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_35/concat:0', description=\"created by layer 'concatenate_35'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_204/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_204'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_205/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_205'\")\n","conv9 shape: (None, 512, 512, 2)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_215/Sigmoid:0', description=\"created by layer 'conv2d_215'\")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hoopnk60rM7q"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-g0J-nAT0kxx"},"source":["  \n","from __future__ import division, print_function\n","# coding=utf-8\n","import sys\n","import os\n","import glob\n","import re\n","import numpy as np\n","\n","# Keras\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.models import load_model\n","from keras.preprocessing import image\n","\n","# Flask utils\n","from flask import Flask, redirect, url_for, request, render_template\n","from werkzeug.utils import secure_filename\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On-ZIG4c_nWp","executionInfo":{"status":"ok","timestamp":1624703752985,"user_tz":-60,"elapsed":7123,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"5be3e174-6888-4139-ea86-e6453a8a19d2"},"source":["!pip install gevent"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting gevent\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent) (57.0.0)\n","Collecting zope.event\n","  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent) (1.1.0)\n","Collecting zope.interface\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n","\u001b[K     |████████████████████████████████| 256kB 42.4MB/s \n","\u001b[?25hInstalling collected packages: zope.event, zope.interface, gevent\n","Successfully installed gevent-21.1.2 zope.event-4.5.0 zope.interface-5.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K7AIbWb2_x_p"},"source":["from gevent.pywsgi import WSGIServer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"le_y6FYhW0cC","executionInfo":{"status":"ok","timestamp":1624703758379,"user_tz":-60,"elapsed":3845,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"1c92dd7f-455f-4869-97eb-267a0b70437e"},"source":["!pip install flask-ngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJ9LkgxDW2oB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PVm3L81_3yW"},"source":["\n","from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","app = Flask(__name__)\n","run_with_ngrok(app)   \n","  \n","\n","\n","\n","@app.route('/', methods=['GET'])\n","def index():\n","    # Main page\n","    return render_template('index.html')\n","\n","if __name__ == '__main__':\n"," app.run()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1nU162GANws","executionInfo":{"status":"ok","timestamp":1624705311548,"user_tz":-60,"elapsed":1117,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"a8938839-474d-4a73-e17a-fafcd651dc97"},"source":["!git clone https://github.com/krishnaik06/Deployment-Deep-Learning-Model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Deployment-Deep-Learning-Model'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17\u001b[K\n","Unpacking objects: 100% (17/17), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"889g-c9I_Auv","executionInfo":{"status":"ok","timestamp":1624705348959,"user_tz":-60,"elapsed":252,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"9bf69c09-5d21-4931-f557-bbef2b1bac05"},"source":[" cd Deployment-Deep-Learning-Model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/Deployment-Deep-Learning-Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d3UkSmNC_DL_"},"source":["from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","from __future__ import division, print_function\n","# coding=utf-8\n","import sys\n","import os\n","import glob\n","import re\n","import numpy as np\n","\n","# Keras\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.models import load_model\n","from keras.preprocessing import image\n","\n","# Flask utils\n","from flask import Flask, redirect, url_for, request, render_template\n","from werkzeug.utils import secure_filename\n","from gevent.pywsgi import WSGIServer\n","\n","# Define a flask app\n","app = Flask(__name__)\n","run_with_ngrok(app)  \n","\n","# Model saved with Keras model.save()\n","\n","\n","# Load your trained model\n","myunet = myUnet()\n","model = myunet.get_unet()\n","\n","          # Necessary\n","# print('Model loaded. Start serving...')\n","\n","# You can also use pretrained model from Keras\n","# Check https://keras.io/applications/\n","#from keras.applications.resnet50 import ResNet50\n","#model = ResNet50(weights='imagenet')\n","#model.save('')\n","print('Model loaded. Check http://127.0.0.1:5000/')\n","model.load_weights('./static/unet_model.hdf5')\n","\n","def model_predict(img_path, model):\n","   # img = image.load_img(img_path, target_size=(512,512))\n","\n","     i = 0\n","     print('Creating test images...')\n","     imgs = glob.glob(img_path + \"/*.\" + self.img_type)\n","     imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","     testpathlist = []\n","\n","     for imgname in imgs:\n","            testpath = imgname\n","            testpathlist.append(testpath)\n","            img = load_img(testpath, grayscale=False, target_size=[512, 512])\n","            img = img_to_array(img)\n","            imgdatas[i] = img\n","            i += 1\n","\n","            np.save('./uploads/imgs_test.npy', imgdatas)\n","            print('Saving to imgs_test.npy files done.')\n","            imgs_test = np.load(\"./uploads/imgs_test.npy\")\n","            imgs_test = imgs_test.astype('float32')\n","            imgs_test /= 255\n","            preds = model.predict(imgs_test, batch_size=1, verbose=1)\n","\n","            \n","            return preds\n","\n","\n","\n","@app.route('/', methods=['GET'])\n","def index():\n","    # Main page\n","    return render_template('index.html')\n","\n","\n","@app.route('/predict', methods=['GET', 'POST'])\n","def upload():\n","    if request.method == 'POST':\n","        # Get the file from post request\n","        f = request.files['file']\n","\n","        # Save the file to ./uploads\n","        basepath = os.path.dirname(__file__)\n","        file_path = os.path.join(\n","            basepath, 'uploads', secure_filename(f.filename))\n","        f.save(file_path)\n","\n","        # Make prediction\n","        preds = model_predict(file_path, model)\n","\n","        # Process your result for human\n","        pred_class = preds.argmax(axis=-1)            # Simple argmax\n","        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n","        result = str(pred_class[0][0][1])               # Convert to string\n","        return result\n","    return None\n","#------------------------------------------------------\n","\n","\n","\n","#------------------------------------------------------\n","\n","\n","\n","#---------------------------------------------------------------\n","if __name__ == '__main__':\n","    app.run()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-Sy6s6rI4QQ"},"source":[""],"execution_count":null,"outputs":[]}]}