{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aa.ipynb","provenance":[],"mount_file_id":"1dVwTNufmaf8cLS30D0MK6J3eMCMBSEh7","authorship_tag":"ABX9TyPiEh4THIN7+cOLkvRZuTJ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"dWzFixuBq-E7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624718397270,"user_tz":-60,"elapsed":25883,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"1d274bfa-48df-4f90-f26e-97aa7b5ca563"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gsY_v1dVrDQ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624736111557,"user_tz":-60,"elapsed":26285,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"0c677c5c-11e4-4969-f039-64ebcf38dd78"},"source":["\n","from keras.preprocessing.image import img_to_array, load_img\n","import numpy as np\n","import glob\n","\n","\n","class dataProcess(object):\n","    def __init__(self, out_rows, out_cols, data_path=\"/content/drive/MyDrive/U-Net2/data/train/images\", label_path=\"/content/drive/MyDrive/U-Net2/data/train/labels\",\n","                 test_path=\"/content/drive/MyDrive/U-Net2/data/test/images\", npy_path=\"/content/drive/MyDrive/U-Net2/data/npydata\", img_type=\"jpg\"):\n","        self.out_rows = out_rows\n","        self.out_cols = out_cols\n","        self.data_path = data_path\n","        self.label_path = label_path\n","        self.img_type = img_type\n","        self.test_path = test_path\n","        self.npy_path = npy_path\n","\n","   \n","    def create_train_data(self):\n","        i = 0\n","        print('Creating training images...')\n","        imgs = glob.glob(self.data_path+\"/*.\"+self.img_type)\n","        print(len(imgs))\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n","\n","        for x in range(len(imgs)):\n","            imgpath = imgs[x]\n","            pic_name = imgpath.split('/')[-1]\n","            labelpath = self.label_path + '/' + pic_name\n","            img = load_img(imgpath, grayscale=False, target_size=[512, 512])\n","            label = load_img(labelpath, grayscale=True, target_size=[512, 512])\n","            img = img_to_array(img)\n","            label = img_to_array(label)\n","            imgdatas[i] = img\n","            imglabels[i] = label\n","            if i % 100 == 0:\n","                print('Done:', len(imgs),' images')\n","            i += 1\n","\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n","        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n","        print('Saving to .npy files done.')\n","\n","    def create_test_data(self):\n","        i = 0\n","        print('Creating test images...')\n","        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        testpathlist = []\n","\n","        for imgname in imgs:\n","            testpath = imgname\n","            testpathlist.append(testpath)\n","            img = load_img(testpath, grayscale=False, target_size=[512, 512])\n","            img = img_to_array(img)\n","            imgdatas[i] = img\n","            i += 1\n","\n","        txtname = '/content/drive/MyDrive/U-Net2/data/results/pic.txt'\n","        with open(txtname, 'w') as f:\n","            for i in range(len(testpathlist)):\n","                f.writelines(testpathlist[i] + '\\n')\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n","        print('Saving to imgs_test.npy files done.')\n","\n","    def load_train_data(self):\n","        print('load train images...')\n","        imgs_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_train.npy\")\n","        imgs_mask_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_mask_train.npy\")\n","        imgs_train = imgs_train.astype('float32')\n","        imgs_mask_train = imgs_mask_train.astype('float32')\n","        imgs_train /= 255\n","        imgs_mask_train /= 255\n","        imgs_mask_train[imgs_mask_train > 0.5] = 1  \n","        imgs_mask_train[imgs_mask_train <= 0.5] = 0 \n","        return imgs_train, imgs_mask_train\n","\n","    def load_test_data(self):\n","        print('-' * 30)\n","        print('load test images...')\n","        print('-' * 30)\n","        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n","        imgs_test = imgs_test.astype('float32')\n","        imgs_test /= 255\n","        return imgs_test\n","\n","\n","\n","if __name__ == \"__main__\":\n","    mydata = dataProcess(512, 512)\n","    mydata.create_train_data()\n","    mydata.create_test_data()\n","\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import array_to_img\n","import cv2\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating training images...\n","36\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["Done: 36  images\n","loading done\n","Saving to .npy files done.\n","Creating test images...\n","loading done\n","Saving to imgs_test.npy files done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QkPzC_FErFJU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624736115838,"user_tz":-60,"elapsed":2562,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"0fcbef5e-d314-42f5-e877-fb84d25eef9a"},"source":["# -*- coding:utf-8 -*-\n","\n","class myUnet(object):\n","      def __init__(self, img_rows=512, img_cols=512):\n","        self.img_rows = img_rows\n","        self.img_cols = img_cols\n","      def load_data(self):\n","        mydata = dataProcess(self.img_rows, self.img_cols)\n","        imgs_train, imgs_mask_train = mydata.load_train_data()\n","        imgs_test = mydata.load_test_data()\n","        return imgs_train, imgs_mask_train, imgs_test\n","      def get_unet(self):\n","        inputs = Input((self.img_rows, self.img_cols, 3))\n","\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","        # print(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","        print (\"pool1 shape:\", pool1.shape)\n","\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","        print (\"pool2 shape:\", pool2.shape)\n","\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","        print (\"pool3 shape:\", pool3.shape)\n","\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","        conv4 = BatchNormalization()(conv4)\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","        conv4 = BatchNormalization()(conv4)\n","        drop4 = Dropout(0.5)(conv4)\n","        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n","        conv5 = BatchNormalization()(conv5)\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","        conv5 = BatchNormalization()(conv5)\n","        drop5 = Dropout(0.5)(conv5)\n","\n","        up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n","        up6 = BatchNormalization()(up6)\n","        merge6 = concatenate([drop4, up6], axis=3)\n","        print(up6)\n","        print(merge6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv6))\n","        up7 = BatchNormalization()(up7)\n","        merge7 = concatenate([conv3, up7], axis=3)\n","        print(up7)\n","        print(merge7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","        conv7 = BatchNormalization()(conv7)\n","        print(conv7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n","        print(conv7)\n","        conv7 = BatchNormalization()(conv7)\n","        up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv7))\n","        up8 = BatchNormalization()(up8)\n","        merge8 = concatenate([conv2, up8], axis=3)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n","        conv8 = BatchNormalization()(conv8)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n","        conv8 = BatchNormalization()(conv8)\n","        up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv8))\n","        up9 = BatchNormalization()(up9)\n","        merge9 = concatenate([conv1, up9], axis=3)\n","        print(up9)\n","        print(merge9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print (\"conv9 shape:\", conv9.shape)\n","\n","        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n","        print(conv10)\n","        model = Model(inputs=inputs, outputs=conv10)\n","\n","        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","        return model\n","      def train(self):\n","        print(\"loading data\")\n","        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n","        print(\"loading data done\")\n","        model = self.get_unet()\n","        print(\"got unet\")\n","        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n","        print('Fitting model...')\n","        model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=100, verbose=1,\n","                  validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n","        model.save_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","        print('predict test data')\n","        imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","        np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","\n","      def save_img(self):\n","        print(\"array to image\")\n","        imgs = np.load('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy')\n","        piclist = []\n","        for line in open(\"/content/drive/MyDrive/U-Net2/data/results/pic.txt\"):\n","            line = line.strip()\n","            picname = line.split('/')[-1]\n","            piclist.append(picname)\n","        print(len(piclist))\n","        for i in range(imgs.shape[0]):\n","            path = \"/content/drive/MyDrive/U-Net2/data/test/\" + piclist[i]\n","            img = imgs[i]\n","            img = array_to_img(img)\n","            img.save(path)\n","            cv_pic = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","            cv_pic = cv2.resize(cv_pic,(1918,1280),interpolation=cv2.INTER_CUBIC)\n","            binary, cv_save = cv2.threshold(cv_pic, 127, 255, cv2.THRESH_BINARY)\n","            cv2.imwrite(path, cv_save)\n","      def load_model_weights(self, model):\n","        model.load_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","\n","\n","\n","myunet = myUnet()\n","model = myunet.get_unet()\n","    # model.summary()\n","    # plot_model(model, to_file='model.png')\n","    # Uncomment the below line if you want to re-train a previously trained model \n","#myunet.load_model_weights(model)\n","#imgs_test = mydata.load_test_data()\n","#imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","#np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","#myunet.save_img()\n","\n","#myunet.train()    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["conv1 shape: (None, 512, 512, 64)\n","conv1 shape: (None, 512, 512, 64)\n","pool1 shape: (None, 256, 256, 64)\n","conv2 shape: (None, 256, 256, 128)\n","conv2 shape: (None, 256, 256, 128)\n","pool2 shape: (None, 128, 128, 128)\n","conv3 shape: (None, 128, 128, 256)\n","conv3 shape: (None, 128, 128, 256)\n","pool3 shape: (None, 64, 64, 256)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='batch_normalization_10/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_10'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_12/Relu:0', description=\"created by layer 'conv2d_12'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_13/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_13'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_14/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_14'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_15/Relu:0', description=\"created by layer 'conv2d_15'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_19/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_19'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_3/concat:0', description=\"created by layer 'concatenate_3'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_20/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_20'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_21/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_21'\")\n","conv9 shape: (None, 512, 512, 2)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_23/Sigmoid:0', description=\"created by layer 'conv2d_23'\")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hoopnk60rM7q"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-g0J-nAT0kxx"},"source":["  \n","from __future__ import division, print_function\n","# coding=utf-8\n","import sys\n","import os\n","import glob\n","import re\n","import numpy as np\n","\n","# Keras\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.models import load_model\n","from keras.preprocessing import image\n","\n","# Flask utils\n","from flask import Flask, redirect, url_for, request, render_template\n","from werkzeug.utils import secure_filename\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On-ZIG4c_nWp","executionInfo":{"status":"ok","timestamp":1624736171120,"user_tz":-60,"elapsed":6258,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"1b569ecc-6126-4155-9729-41a0c0c18751"},"source":["!pip install gevent"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting gevent\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 5.3MB/s \n","\u001b[?25hCollecting zope.event\n","  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent) (57.0.0)\n","Collecting zope.interface\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n","\u001b[K     |████████████████████████████████| 256kB 37.7MB/s \n","\u001b[?25hInstalling collected packages: zope.event, zope.interface, gevent\n","Successfully installed gevent-21.1.2 zope.event-4.5.0 zope.interface-5.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K7AIbWb2_x_p","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"error","timestamp":1624736128499,"user_tz":-60,"elapsed":495,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"a068dc51-d162-4888-fc2a-cc5dac599b98"},"source":["from gevent.pywsgi import WSGIServer\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-004f07f0d3e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywsgi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWSGIServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gevent'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"le_y6FYhW0cC","executionInfo":{"status":"ok","timestamp":1624736133406,"user_tz":-60,"elapsed":4271,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"cbfb0963-6f2e-4a11-da29-f1be590d790c"},"source":["!pip install flask-ngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJ9LkgxDW2oB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PVm3L81_3yW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624736141976,"user_tz":-60,"elapsed":3201,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"4c6de3d6-08f1-4b05-fe78-8b19c4696ada"},"source":["\n","from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","app = Flask(__name__)\n","run_with_ngrok(app)   \n","  \n","\n","\n","\n","@app.route('/', methods=['GET'])\n","def index():\n","    # Main page\n","    return render_template('index.html')\n","\n","if __name__ == '__main__':\n"," app.run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://267510202b85.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1nU162GANws","executionInfo":{"status":"ok","timestamp":1624735997608,"user_tz":-60,"elapsed":1017,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"d7bafe32-e76f-4f1f-9533-4912f8306d51"},"source":["!git clone https://github.com/krishnaik06/Deployment-Deep-Learning-Model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Deployment-Deep-Learning-Model'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17\u001b[K\n","Unpacking objects: 100% (17/17), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"889g-c9I_Auv","executionInfo":{"status":"ok","timestamp":1624736020803,"user_tz":-60,"elapsed":295,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"faa4ed64-e995-4b08-e503-c62ce9d16c8f"},"source":[" cd Deployment-Deep-Learning-Model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/Deployment-Deep-Learning-Model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GxcVVcU61tYn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3UkSmNC_DL_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624736445819,"user_tz":-60,"elapsed":207566,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"0150636d-ca32-4db5-8c4e-712ba26d0635"},"source":["from flask import Flask\n","from flask_ngrok import run_with_ngrok\n","from __future__ import division, print_function\n","# coding=utf-8\n","import sys\n","import os\n","import glob\n","import re\n","import numpy as np\n","\n","# Keras\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.models import load_model\n","from keras.preprocessing import image\n","\n","# Flask utils\n","from flask import Flask, redirect, url_for, request, render_template\n","from werkzeug.utils import secure_filename\n","from gevent.pywsgi import WSGIServer\n","\n","# Define a flask app\n","app = Flask(__name__)\n","run_with_ngrok(app)  \n","\n","# Model saved with Keras model.save()\n","\n","\n","# Load your trained model\n","myunet = myUnet()\n","model = myunet.get_unet()\n","\n","          # Necessary\n","# print('Model loaded. Start serving...')\n","\n","# You can also use pretrained model from Keras\n","# Check https://keras.io/applications/\n","#from keras.applications.resnet50 import ResNet50\n","#model = ResNet50(weights='imagenet')\n","#model.save('')\n","print('Model loaded. Check http://127.0.0.1:5000/')\n","#model.load_weights('./static/unet_model.hdf5')\n","\n","def model_predict(img_path, model):\n","   # img = image.load_img(img_path, target_size=(512,512))\n","\n","     i = 0\n","     print('Creating test images...')\n","     imgs = glob.glob(img_path + \"/*.\" + self.img_type)\n","     imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","     testpathlist = []\n","\n","     for imgname in imgs:\n","            testpath = imgname\n","            testpathlist.append(testpath)\n","            img = load_img(testpath, grayscale=False, target_size=[512, 512])\n","            img = img_to_array(img)\n","            imgdatas[i] = img\n","            i += 1\n","\n","            np.save('./uploads/imgs_test.npy', imgdatas)\n","            print('Saving to imgs_test.npy files done.')\n","            imgs_test = np.load(\"./uploads/imgs_test.npy\")\n","            imgs_test = imgs_test.astype('float32')\n","            imgs_test /= 255\n","            preds = model.predict(imgs_test, batch_size=1, verbose=1)\n","\n","            \n","            return preds\n","\n","\n","\n","@app.route('/', methods=['GET'])\n","def index():\n","    # Main page\n","    return render_template('index.html')\n","\n","\n","@app.route('/predict', methods=['GET', 'POST'])\n","def upload():\n","    if request.method == 'POST':\n","        # Get the file from post request\n","        f = request.files['file']\n","\n","        # Save the file to ./uploads\n","        basepath = os.path.dirname(__file__)\n","        file_path = os.path.join(\n","            basepath, 'uploads', secure_filename(f.filename))\n","        f.save(file_path)\n","\n","        # Make prediction\n","        preds = model_predict(file_path, model)\n","\n","        # Process your result for human\n","        pred_class = preds.argmax(axis=-1)            # Simple argmax\n","        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n","        result = str(pred_class[0][0][1])               # Convert to string\n","        return result\n","    return None\n","#------------------------------------------------------\n","\n","\n","\n","#------------------------------------------------------\n","\n","\n","\n","#---------------------------------------------------------------\n","if __name__ == '__main__':\n","    app.run()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conv1 shape: (None, 512, 512, 64)\n","conv1 shape: (None, 512, 512, 64)\n","pool1 shape: (None, 256, 256, 64)\n","conv2 shape: (None, 256, 256, 128)\n","conv2 shape: (None, 256, 256, 128)\n","pool2 shape: (None, 128, 128, 128)\n","conv3 shape: (None, 128, 128, 256)\n","conv3 shape: (None, 128, 128, 256)\n","pool3 shape: (None, 64, 64, 256)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='batch_normalization_56/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_56'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate_8/concat:0', description=\"created by layer 'concatenate_8'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_59/Relu:0', description=\"created by layer 'conv2d_59'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_60/Relu:0', description=\"created by layer 'conv2d_60'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_59/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_59'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_9/concat:0', description=\"created by layer 'concatenate_9'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_60/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_60'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_63/Relu:0', description=\"created by layer 'conv2d_63'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_65/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_65'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_11/concat:0', description=\"created by layer 'concatenate_11'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_66/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_66'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_67/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_67'\")\n","conv9 shape: (None, 512, 512, 2)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_71/Sigmoid:0', description=\"created by layer 'conv2d_71'\")\n","Model loaded. Check http://127.0.0.1:5000/\n"," * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"," * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://5322c275a353.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [26/Jun/2021 19:37:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [26/Jun/2021 19:37:33] \"\u001b[37mGET /static/css/main.css HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [26/Jun/2021 19:37:33] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [26/Jun/2021 19:37:36] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","[2021-06-26 19:39:21,889] ERROR in app: Exception on /predict [POST]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n","    response = self.full_dispatch_request()\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n","    rv = self.handle_user_exception(e)\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n","    reraise(exc_type, exc_value, tb)\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 39, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n","    rv = self.dispatch_request()\n","  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n","    return self.view_functions[rule.endpoint](**req.view_args)\n","  File \"<ipython-input-11-65cbf52498bc>\", line 85, in upload\n","    basepath = os.path.dirname(__file__)\n","NameError: name '__file__' is not defined\n","127.0.0.1 - - [26/Jun/2021 19:39:21] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"i-Sy6s6rI4QQ"},"source":[""],"execution_count":null,"outputs":[]}]}