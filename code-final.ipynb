{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code-final.ipynb","provenance":[],"authorship_tag":"ABX9TyP+Xz19jvBkpN8WPQlo1mNk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"dWzFixuBq-E7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624713691221,"user_tz":-60,"elapsed":32244,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"01567fe6-5ccc-45a5-ba6b-ae2b484252f4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gsY_v1dVrDQ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624713729692,"user_tz":-60,"elapsed":38483,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"f77f594a-0ba4-4fb8-c80b-3c9628003ecf"},"source":["\n","from keras.preprocessing.image import img_to_array, load_img\n","import numpy as np\n","import glob\n","\n","\n","class dataProcess(object):\n","    def __init__(self, out_rows, out_cols, data_path=\"/content/drive/MyDrive/U-Net2/data/train/images\", label_path=\"/content/drive/MyDrive/U-Net2/data/train/labels\",\n","                 test_path=\"/content/drive/MyDrive/U-Net2/data/test/images\", npy_path=\"/content/drive/MyDrive/U-Net2/data/npydata\", img_type=\"jpg\"):\n","        self.out_rows = out_rows\n","        self.out_cols = out_cols\n","        self.data_path = data_path\n","        self.label_path = label_path\n","        self.img_type = img_type\n","        self.test_path = test_path\n","        self.npy_path = npy_path\n","\n","   \n","    def create_train_data(self):\n","        i = 0\n","        print('Creating training images...')\n","        imgs = glob.glob(self.data_path+\"/*.\"+self.img_type)\n","        print(len(imgs))\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n","\n","        for x in range(len(imgs)):\n","            imgpath = imgs[x]\n","            pic_name = imgpath.split('/')[-1]\n","            labelpath = self.label_path + '/' + pic_name\n","            img = load_img(imgpath, grayscale=False, target_size=[512, 512])\n","            label = load_img(labelpath, grayscale=True, target_size=[512, 512])\n","            img = img_to_array(img)\n","            label = img_to_array(label)\n","            imgdatas[i] = img\n","            imglabels[i] = label\n","            if i % 100 == 0:\n","                print('Done:', len(imgs),' images')\n","            i += 1\n","\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n","        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n","        print('Saving to .npy files done.')\n","\n","    def create_test_data(self):\n","        i = 0\n","        print('Creating test images...')\n","        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n","        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n","        testpathlist = []\n","\n","        for imgname in imgs:\n","            testpath = imgname\n","            testpathlist.append(testpath)\n","            img = load_img(testpath, grayscale=False, target_size=[512, 512])\n","            img = img_to_array(img)\n","            imgdatas[i] = img\n","            i += 1\n","\n","        txtname = '/content/drive/MyDrive/U-Net2/data/results/pic.txt'\n","        with open(txtname, 'w') as f:\n","            for i in range(len(testpathlist)):\n","                f.writelines(testpathlist[i] + '\\n')\n","        print('loading done')\n","        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n","        print('Saving to imgs_test.npy files done.')\n","\n","    def load_train_data(self):\n","        print('load train images...')\n","        imgs_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_train.npy\")\n","        imgs_mask_train = np.load(\"/content/drive/MyDrive/U-Net2/data/npydata\" + \"/imgs_mask_train.npy\")\n","        imgs_train = imgs_train.astype('float32')\n","        imgs_mask_train = imgs_mask_train.astype('float32')\n","        imgs_train /= 255\n","        imgs_mask_train /= 255\n","        imgs_mask_train[imgs_mask_train > 0.5] = 1  \n","        imgs_mask_train[imgs_mask_train <= 0.5] = 0 \n","        return imgs_train, imgs_mask_train\n","\n","    def load_test_data(self):\n","        print('-' * 30)\n","        print('load test images...')\n","        print('-' * 30)\n","        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n","        imgs_test = imgs_test.astype('float32')\n","        imgs_test /= 255\n","        return imgs_test\n","\n","\n","\n","if __name__ == \"__main__\":\n","    mydata = dataProcess(512, 512)\n","    mydata.create_train_data()\n","    mydata.create_test_data()\n","\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import array_to_img\n","import cv2\n","\n","\n","\n","\n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Creating training images...\n","36\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["Done: 36  images\n","loading done\n","Saving to .npy files done.\n","Creating test images...\n","loading done\n","Saving to imgs_test.npy files done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QkPzC_FErFJU","colab":{"base_uri":"https://localhost:8080/","height":861},"executionInfo":{"status":"error","timestamp":1624713745215,"user_tz":-60,"elapsed":15555,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"e621442b-05dc-4bce-9468-4f0161eb08c2"},"source":["# -*- coding:utf-8 -*-\n","\n","class myUnet(object):\n","      def __init__(self, img_rows=512, img_cols=512):\n","        self.img_rows = img_rows\n","        self.img_cols = img_cols\n","      def load_data(self):\n","        mydata = dataProcess(self.img_rows, self.img_cols)\n","        imgs_train, imgs_mask_train = mydata.load_train_data()\n","        imgs_test = mydata.load_test_data()\n","        return imgs_train, imgs_mask_train, imgs_test\n","      def get_unet(self):\n","        inputs = Input((self.img_rows, self.img_cols, 3))\n","\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","        # print(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","        conv1 = BatchNormalization()(conv1)\n","        print (\"conv1 shape:\", conv1.shape)\n","        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","        print (\"pool1 shape:\", pool1.shape)\n","\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","        print (\"conv2 shape:\", conv2.shape)\n","        conv2 = BatchNormalization()(conv2)\n","        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","        print (\"pool2 shape:\", pool2.shape)\n","\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","        print (\"conv3 shape:\", conv3.shape)\n","        conv3 = BatchNormalization()(conv3)\n","        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","        print (\"pool3 shape:\", pool3.shape)\n","\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","        conv4 = BatchNormalization()(conv4)\n","        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","        conv4 = BatchNormalization()(conv4)\n","        drop4 = Dropout(0.5)(conv4)\n","        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n","        conv5 = BatchNormalization()(conv5)\n","        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","        conv5 = BatchNormalization()(conv5)\n","        drop5 = Dropout(0.5)(conv5)\n","\n","        up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n","        up6 = BatchNormalization()(up6)\n","        merge6 = concatenate([drop4, up6], axis=3)\n","        print(up6)\n","        print(merge6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","        print(conv6)\n","        conv6 = BatchNormalization()(conv6)\n","        up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv6))\n","        up7 = BatchNormalization()(up7)\n","        merge7 = concatenate([conv3, up7], axis=3)\n","        print(up7)\n","        print(merge7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","        conv7 = BatchNormalization()(conv7)\n","        print(conv7)\n","        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n","        print(conv7)\n","        conv7 = BatchNormalization()(conv7)\n","        up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv7))\n","        up8 = BatchNormalization()(up8)\n","        merge8 = concatenate([conv2, up8], axis=3)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n","        conv8 = BatchNormalization()(conv8)\n","        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n","        conv8 = BatchNormalization()(conv8)\n","        up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","            UpSampling2D(size=(2, 2))(conv8))\n","        up9 = BatchNormalization()(up9)\n","        merge9 = concatenate([conv1, up9], axis=3)\n","        print(up9)\n","        print(merge9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print(conv9)\n","        conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n","        conv9 = BatchNormalization()(conv9)\n","        print (\"conv9 shape:\", conv9.shape)\n","\n","        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n","        print(conv10)\n","        model = Model(inputs=inputs, outputs=conv10)\n","\n","        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","        return model\n","      def train(self):\n","        print(\"loading data\")\n","        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n","        print(\"loading data done\")\n","        model = self.get_unet()\n","        print(\"got unet\")\n","        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n","        print('Fitting model...')\n","        model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=100, verbose=1,\n","                  validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n","        model.save_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","        print('predict test data')\n","        imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","        np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","\n","      def save_img(self):\n","        print(\"array to image\")\n","        imgs = np.load('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy')\n","        piclist = []\n","        for line in open(\"/content/drive/MyDrive/U-Net2/data/results/pic.txt\"):\n","            line = line.strip()\n","            picname = line.split('/')[-1]\n","            piclist.append(picname)\n","        print(len(piclist))\n","        for i in range(imgs.shape[0]):\n","            path = \"/content/drive/MyDrive/U-Net2/data/test/\" + piclist[i]\n","            img = imgs[i]\n","            img = array_to_img(img)\n","            img.save(path)\n","            cv_pic = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","            cv_pic = cv2.resize(cv_pic,(1918,1280),interpolation=cv2.INTER_CUBIC)\n","            binary, cv_save = cv2.threshold(cv_pic, 127, 255, cv2.THRESH_BINARY)\n","            cv2.imwrite(path, cv_save)\n","      def load_model_weights(self, model):\n","        model.load_weights('/content/drive/MyDrive/U-Net2/data/results/unet_model.hdf5')\n","\n","\n","\n","myunet = myUnet()\n","model = myunet.get_unet()\n","    # model.summary()\n","    # plot_model(model, to_file='model.png')\n","    # Uncomment the below line if you want to re-train a previously trained model \n","myunet.load_model_weights(model)\n","imgs_test = mydata.load_test_data()\n","imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n","np.save('/content/drive/MyDrive/U-Net2/data/results/imgs_mask_test.npy', imgs_mask_test)\n","myunet.save_img()\n","\n","#myunet.train()  \n","save_path = '/content/drive/MyDrive/U-Net2/data/results/'\n","model.save(model, save_path)  "],"execution_count":4,"outputs":[{"output_type":"stream","text":["conv1 shape: (None, 512, 512, 64)\n","conv1 shape: (None, 512, 512, 64)\n","pool1 shape: (None, 256, 256, 64)\n","conv2 shape: (None, 256, 256, 128)\n","conv2 shape: (None, 256, 256, 128)\n","pool2 shape: (None, 128, 128, 128)\n","conv3 shape: (None, 128, 128, 256)\n","conv3 shape: (None, 128, 128, 256)\n","pool3 shape: (None, 64, 64, 256)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='batch_normalization_10/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_10'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 512), dtype=tf.float32, name=None), name='conv2d_12/Relu:0', description=\"created by layer 'conv2d_12'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_13/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_13'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 512), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='batch_normalization_14/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_14'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 256), dtype=tf.float32, name=None), name='conv2d_15/Relu:0', description=\"created by layer 'conv2d_15'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_19/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_19'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 128), dtype=tf.float32, name=None), name='concatenate_3/concat:0', description=\"created by layer 'concatenate_3'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_20/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_20'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 64), dtype=tf.float32, name=None), name='batch_normalization_21/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_21'\")\n","conv9 shape: (None, 512, 512, 2)\n","KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32, name=None), name='conv2d_23/Sigmoid:0', description=\"created by layer 'conv2d_23'\")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["------------------------------\n","load test images...\n","------------------------------\n","1/1 [==============================] - 5s 5s/step\n","array to image\n","1\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e7eaebc87c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m#myunet.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/U-Net2/data/results/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2112\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m   def save_weights(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    133\u001b[0m   if (save_format == 'h5' or\n\u001b[1;32m    134\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m       saving_utils.is_hdf5_filepath(filepath)):\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;31m# TODO(b/130258301): add utility method for detecting model type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     if (not model._is_graph_network and  # pylint:disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mis_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[1;32m    326\u001b[0m           filepath.endswith('.hdf5'))\n","\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'endswith'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYWlDA41PsjJ","executionInfo":{"status":"ok","timestamp":1624709918820,"user_tz":-60,"elapsed":8771,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"abf3576b-7022-460f-ed56-8408ddaf23c3"},"source":["save_path = '/content/drive/MyDrive/U-Net2/data/results/'\n","tf.saved_model.save(model, save_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n","\n","FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/U-Net2/data/results/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uajg9jn3XnqR","executionInfo":{"status":"ok","timestamp":1624711792862,"user_tz":-60,"elapsed":270,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"23733664-4a93-4ed7-f9e2-17fc136901d2"},"source":["tf.keras.models.save_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function tensorflow.python.keras.saving.save.save_model>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"hoopnk60rM7q"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsdZ_6aLJ1z9","executionInfo":{"status":"ok","timestamp":1624710050927,"user_tz":-60,"elapsed":266,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"348eb679-f5a7-4207-e0db-280f03ddb147"},"source":["!ls  '/content/drive/MyDrive/U-Net2/data/results/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["assets\timgs_mask_test.npy  pic.txt  saved_model.pb  unet_model.hdf5  variables\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcjXmFt-KCo3","executionInfo":{"status":"ok","timestamp":1624710044255,"user_tz":-60,"elapsed":333,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"a7373c8a-f2ae-4d36-c22d-a388fb2dea91"},"source":["import socket\n","print(socket.gethostbyname(socket.gethostname()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["172.28.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"QXeQV0HDLIgP","executionInfo":{"status":"error","timestamp":1624711805176,"user_tz":-60,"elapsed":303,"user":{"displayName":"pfe iav","photoUrl":"","userId":"10500839342802673727"}},"outputId":"eef7c470-8aa1-4f3d-b38f-1491564add5b"},"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","from flask import Flask, jsonify, make_response, request\n","import threading\n","\n","app = Flask(__name__)\n","padding_size = 1000\n","model = tf.keras.models.load_model('/content/drive/MyDrive/U-Net2/data/results/saved_model.pb')\n","text_encoder = tfds.features.text.TokenTextEncoder.load_from_file(\"/content/drive/My Drive/Colab/Amozon Sentiment Analysis/sa_encoder.vocab\")\n","\n","print('Model and Vocabalory loaded.......')\n","\n","@app.route(\"/\")\n","def hello():\n","    return \"I am alive!\"\n","\n","def pad_to_size(vec, size):\n","    zeros = [0] * (size - len(vec))\n","    vec.extend(zeros)\n","    return vec\n","\n","\n","def predict_fn(predict_text, pad_size):\n","    encoded_text = text_encoder.encode(predict_text)\n","    encoded_text = pad_to_size(encoded_text, pad_size)\n","    encoded_text = tf.cast(encoded_text, tf.int64)\n","    predictions = model.predict(tf.expand_dims(encoded_text, 0))\n","\n","    return (predictions.tolist())\n","\n","\n","@app.route('/seclassifier', methods=['POST'])\n","def predict_sentiment():\n","    text = request.get_json()['text']\n","    print(text)\n","    predictions = predict_fn(text, padding_size)\n","    sentiment = 'positive' if float(''.join(map(str,predictions[0]))) > 0 else 'Negative'\n","    return jsonify({'predictions ':predictions, 'sentiment ': sentiment})\n","\n","\n","threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':6000}).start()\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-6aaff7643db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpadding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/U-Net2/data/results/saved_model.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenTextEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab/Amozon Sentiment Analysis/sa_encoder.vocab\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 116\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/MyDrive/U-Net2/data/results/saved_model.pb/{saved_model.pbtxt|saved_model.pb}"]}]}]}